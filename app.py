import streamlit as st
import pandas as pd
import requests
from io import StringIO
import unicodedata
import re

# -------------------------
# Helpers
# -------------------------
def remove_diacritics(text: str) -> str:
    if not isinstance(text, str):
        return text
    nfkd = unicodedata.normalize('NFKD', text)
    return ''.join([c for c in nfkd if not unicodedata.combining(c)])

def normalize_text(text: str) -> str:
    # lower, strip, remove extra spaces, remove diacritics
    t = str(text).lower().strip()
    t = re.sub(r'\s+', ' ', t)
    t = remove_diacritics(t)
    return t

def build_mask(df, query, mode='any'):
    """
    mode:
      - 'any' : any token (OR)
      - 'all' : all tokens (AND)
      - 'exact': exact phrase
    """
    if query.strip() == "":
        return pd.Series([False]*len(df), index=df.index)

    # normalize questions once (cached column)
    if '_q_norm' not in df.columns:
        df['_q_norm'] = df['question'].astype(str).apply(normalize_text)

    q_norm = normalize_text(query)

    if mode == 'exact':
        # exact phrase match in normalized text
        mask = df['_q_norm'].str.contains(re.escape(q_norm), na=False)
        return mask

    # tokenize query by spaces
    tokens = [tok for tok in re.split(r'\s+', q_norm) if tok]
    if not tokens:
        return pd.Series([False]*len(df), index=df.index)

    if mode == 'any':
        # any token matches
        mask = pd.Series(False, index=df.index)
        for tok in tokens:
            mask = mask | df['_q_norm'].str.contains(re.escape(tok), na=False)
        return mask

    if mode == 'all':
        # all tokens must be present
        mask = pd.Series(True, index=df.index)
        for tok in tokens:
            mask = mask & df['_q_norm'].str.contains(re.escape(tok), na=False)
        return mask

    # fallback
    return pd.Series([False]*len(df), index=df.index)

# -------------------------
# App UI
# -------------------------
st.set_page_config(page_title="Chatbox Tr·∫Øc Nghi·ªám (T√¨m n√¢ng cao)", layout="centered")
st.title("üîé Chatbox T√¨m C√¢u H·ªèi Tr·∫Øc Nghi·ªám (n√¢ng cao)")

st.markdown("B·∫°n c√≥ th·ªÉ d√°n link RAW GitHub ho·∫∑c upload file CSV (c·ªôt: id, question, correct_answer).")
col1, col2 = st.columns([3,1])

with col1:
    csv_url = st.text_input("üîó D√°n link RAW CSV (t√πy ch·ªçn):", help="V√≠ d·ª•: https://raw.githubusercontent.com/username/repo/main/questions.csv")

with col2:
    uploaded_file = st.file_uploader("üì• Ho·∫∑c t·∫£i file CSV", type=["csv"])

df = None
# load from url if provided
if csv_url and csv_url.strip():
    try:
        r = requests.get(csv_url.strip(), timeout=10)
        r.raise_for_status()
        df = pd.read_csv(StringIO(r.text))
        st.success("‚úÖ ƒê√£ t·∫£i CSV t·ª´ URL")
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i CSV t·ª´ URL: {e}")
        df = None

# if uploader used and df not loaded from url
if uploaded_file and df is None:
    try:
        df = pd.read_csv(uploaded_file)
        st.success("‚úÖ ƒê√£ ƒë·ªçc file CSV upload")
    except Exception as e:
        st.error(f"‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file CSV: {e}")
        df = None

# if df loaded, validate columns
if df is not None:
    required = {"id", "question", "correct_answer"}
    if not required.issubset(set(df.columns)):
        st.error("‚ùå CSV ph·∫£i c√≥ 3 c·ªôt: id, question, correct_answer")
        st.stop()

    # ensure question is str
    df['question'] = df['question'].astype(str)

# search controls
st.markdown("---")
if df is None:
    st.info("‚è≥ H√£y nh·∫≠p link RAW ho·∫∑c upload file CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
else:
    st.write(f"üìö D·ªØ li·ªáu: {len(df)} c√¢u hi·ªán c√≥.")
    # choose mode
    mode = st.selectbox("Ch·∫ø ƒë·ªô t√¨m", options=['any (any token / OR)', 'all (all tokens / AND)', 'exact (exact phrase)'], index=0)
    # map to simple keys
    mode_map = {'any (any token / OR)': 'any', 'all (all tokens / AND)': 'all', 'exact (exact phrase)': 'exact'}

    # session_state for textbox
    if 'keyword' not in st.session_state:
        st.session_state.keyword = ''

    keyword = st.text_input("üîç Nh·∫≠p t·ª´ kh√≥a ƒë·ªÉ t√¨m", key='keyword', placeholder="V√≠ d·ª•: 'kh√¥ng thu·ªôc ƒë·ªëi t∆∞·ª£ng' ho·∫∑c 'SIPAS'")

    def on_search_click():
        # callback used only to trigger re-run and then we clear below after search displayed
        pass

    search_clicked = st.button("T√¨m c√¢u h·ªèi", on_click=on_search_click)

    if search_clicked:
        q = str(keyword).strip()
        if q == "":
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p t·ª´ kh√≥a.")
        else:
            mode_key = mode_map[mode]
            mask = build_mask(df, q, mode=mode_key)
            results = df[mask].copy()

            st.write(f"üîé K·∫øt qu·∫£: {len(results)} c√¢u t√¨m th·∫•y (ch·∫ø ƒë·ªô: {mode_key})")
            if len(results) == 0:
                # show debug hints
                st.info("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£. Th·ª≠ c√°c g·ª£i √Ω sau:")
                st.markdown("""
                - Ki·ªÉm tra ch√≠nh t·∫£ ho·∫∑c th·ª≠ b·ªè d·∫•u (v√≠ d·ª•: `khong thuoc doi tuong`)  
                - Th·ª≠ thay ƒë·ªïi ch·∫ø ƒë·ªô: **any** ho·∫∑c **exact**  
                - Th·ª≠ t√¨m 1 t·ª´ ng·∫Øn h∆°n (v√≠ d·ª•: ch·ªâ `thuoc`)  
                """)
                # show sample of normalized question to help debugging
                sample_norm = normalize_text(q)
                st.write("üîß Debug: chu·ªói t√¨m (normalize):", sample_norm)
                # show first 5 normalized questions for manual check
                st.markdown("V√≠ d·ª• v√†i c√¢u (normalized):")
                tmp = df[['id','question']].head(5).copy()
                tmp['question_normalized'] = tmp['question'].apply(normalize_text)
                st.dataframe(tmp)
            else:
                # display results (only question + correct_answer)
                for _, row in results.iterrows():
                    st.markdown("---")
                    st.markdown("### ‚ùì C√¢u h·ªèi:")
                    # highlight keyword in displayed question (simple highlight on normalized match)
                    # show original question only
                    st.write(row['question'])
                    st.markdown("### ‚úÖ ƒê√°p √°n ƒë√∫ng:")
                    st.success(row['correct_answer'])

            # auto-clear keyword by setting session_state AFTER showing results (via callback trick)
            # streamlit won't allow changing session_state during render triggered by button? it's safe here since it's in on_click no state change; to be safe, we schedule clear using st.experimental_rerun:
            st.session_state.keyword = ""  # clear for next search
            st.experimental_rerun()
